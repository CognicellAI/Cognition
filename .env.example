# Cognition Environment Variables Example
# Copy this file to .env and fill in your values.

# Server Settings
COGNITION_HOST=127.0.0.1
COGNITION_PORT=8000
COGNITION_LOG_LEVEL=info
COGNITION_MAX_SESSIONS=100
COGNITION_SESSION_TIMEOUT_SECONDS=3600

# Workspace Settings
COGNITION_WORKSPACE_ROOT=.

# LLM Provider Selection
# Supported: mock, openai, bedrock, openai_compatible, ollama
COGNITION_LLM_PROVIDER=openai
COGNITION_LLM_MODEL=gpt-4o

# LLM Options
COGNITION_LLM_TEMPERATURE=0.7
COGNITION_LLM_MAX_TOKENS=4096

# OpenAI Credentials
OPENAI_API_KEY=sk-...
OPENAI_API_BASE=https://api.openai.com/v1

# AWS Bedrock Credentials
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=AKIA...
AWS_SECRET_ACCESS_KEY=...
COGNITION_BEDROCK_MODEL_ID=anthropic.claude-3-sonnet-20240229-v1:0

# Ollama Settings
COGNITION_OLLAMA_MODEL=llama3.2
COGNITION_OLLAMA_BASE_URL=http://localhost:11434

# OpenAI Compatible (e.g., OpenRouter, vLLM)
COGNITION_OPENAI_COMPATIBLE_BASE_URL=https://openrouter.ai/api/v1
COGNITION_OPENAI_COMPATIBLE_API_KEY=sk-or-...

# Observability
COGNITION_OTEL_ENABLED=true
COGNITION_OTEL_ENDPOINT=http://localhost:4317
COGNITION_METRICS_PORT=9090

# MLflow Tracing (optional)
COGNITION_MLFLOW_ENABLED=false
COGNITION_MLFLOW_TRACKING_URI=http://localhost:5000
COGNITION_MLFLOW_EXPERIMENT_NAME=cognition

# Persistence
COGNITION_PERSISTENCE_BACKEND=sqlite
COGNITION_PERSISTENCE_URI=.cognition/state.db
